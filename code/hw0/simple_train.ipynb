{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "another-ownership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/moritz/venvs/mltheory/lib/python3.6/site-packages (4.56.0)\n"
     ]
    }
   ],
   "source": [
    "# install: tqdm (progress bars)\n",
    "!pip install tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision.datasets as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-locator",
   "metadata": {},
   "source": [
    "## Load the data (CIFAR-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indoor-trademark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data_cache/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cf105f889544f88d6f55c8ea0695b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data_cache/cifar-10-python.tar.gz to ./data_cache\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def load_cifar(datadir='./data_cache'): # will download ~400MB of data into this dir. Change the dir if neccesary. If using paperspace, you can make this /storage\n",
    "    train_ds = ds.CIFAR10(root=datadir, train=True,\n",
    "                           download=True, transform=None)\n",
    "    test_ds = ds.CIFAR10(root=datadir, train=False,\n",
    "                          download=True, transform=None)\n",
    "\n",
    "    def to_xy(dataset):\n",
    "        X = torch.Tensor(np.transpose(dataset.data, (0, 3, 1, 2))).float() / 255.0  # [0, 1]\n",
    "        Y = torch.Tensor(np.array(dataset.targets)).long()\n",
    "        return X, Y\n",
    "\n",
    "    X_tr, Y_tr = to_xy(train_ds)\n",
    "    X_te, Y_te = to_xy(test_ds)\n",
    "    return X_tr, Y_tr, X_te, Y_te\n",
    "\n",
    "def make_loader(dataset, batch_size=128):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "            shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "X_tr, Y_tr, X_te, Y_te = load_cifar()\n",
    "train_dl = make_loader(TensorDataset(X_tr, Y_tr))\n",
    "test_dl = make_loader(TensorDataset(X_te, Y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-congo",
   "metadata": {},
   "source": [
    "## Training helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reduced-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dl : DataLoader, opt, k = 50):\n",
    "    ''' Trains model for one epoch on the provided dataloader, with optimizer opt. Logs stats every k batches.'''\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    model.cuda()\n",
    "\n",
    "    netLoss = 0.0\n",
    "    nCorrect = 0\n",
    "    nTotal = 0\n",
    "    for i, (xB, yB) in enumerate(tqdm(train_dl)):\n",
    "        opt.zero_grad()\n",
    "        xB, yB = xB.cuda(), yB.cuda()\n",
    "        outputs = model(xB)\n",
    "        loss = loss_func(outputs, yB)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        netLoss += loss.item() * len(xB)\n",
    "        with torch.no_grad():\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            nCorrect += (preds == yB).float().sum()\n",
    "            nTotal += preds.size(0)\n",
    "        \n",
    "        if (i+1) % k == 0:\n",
    "            train_acc = nCorrect/nTotal\n",
    "            avg_loss = netLoss/nTotal\n",
    "            print(f'\\t [Batch {i+1} / {len(train_dl)}] Train Loss: {avg_loss:.3f} \\t Train Acc: {train_acc:.3f}')\n",
    "  \n",
    "    train_acc = nCorrect/nTotal\n",
    "    avg_loss = netLoss/nTotal\n",
    "    return avg_loss, train_acc\n",
    "\n",
    "\n",
    "def evaluate(model, test_dl, loss_func=nn.CrossEntropyLoss().cuda()):\n",
    "    ''' Returns loss, acc'''\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    nCorrect = 0.0\n",
    "    nTotal = 0\n",
    "    net_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for (xb, yb) in test_dl:\n",
    "            xb, yb = xb.cuda(), yb.cuda()\n",
    "            outputs = model(xb)\n",
    "            loss = len(xb) * loss_func(outputs, yb)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            nCorrect += (preds == yb).float().sum()\n",
    "            net_loss += loss\n",
    "            nTotal += preds.size(0)\n",
    "\n",
    "    acc = nCorrect.cpu().item() / float(nTotal)\n",
    "    loss = net_loss.cpu().item() / float(nTotal)\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "remarkable-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "synthetic-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5-Layer CNN for CIFAR\n",
    "## This is the Myrtle5 network by David Page (https://myrtle.ai/learn/how-to-train-your-resnet-4-architecture/)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), x.size(1))\n",
    "\n",
    "def make_cnn(c=64, num_classes=10):\n",
    "    ''' Returns a 5-layer CNN with width parameter c. '''\n",
    "    return nn.Sequential(\n",
    "        # Layer 0\n",
    "        nn.Conv2d(3, c, kernel_size=3, stride=1,\n",
    "                  padding=1, bias=True),\n",
    "        nn.BatchNorm2d(c),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        # Layer 1\n",
    "        nn.Conv2d(c, c*2, kernel_size=3,\n",
    "                  stride=1, padding=1, bias=True),\n",
    "        nn.BatchNorm2d(c*2),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "\n",
    "        # Layer 2\n",
    "        nn.Conv2d(c*2, c*4, kernel_size=3,\n",
    "                  stride=1, padding=1, bias=True),\n",
    "        nn.BatchNorm2d(c*4),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "\n",
    "        # Layer 3\n",
    "        nn.Conv2d(c*4, c*8, kernel_size=3,\n",
    "                  stride=1, padding=1, bias=True),\n",
    "        nn.BatchNorm2d(c*8),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "\n",
    "        # Layer 4\n",
    "        nn.MaxPool2d(4),\n",
    "        Flatten(),\n",
    "        nn.Linear(c*8, num_classes, bias=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "productive-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "technical-chest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d79712abd447c28d14322f18b87b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 6.712 \t Train Acc: 0.156\n",
      "\t [Batch 100 / 391] Train Loss: 4.590 \t Train Acc: 0.182\n",
      "\t [Batch 150 / 391] Train Loss: 3.789 \t Train Acc: 0.204\n",
      "\t [Batch 200 / 391] Train Loss: 3.338 \t Train Acc: 0.226\n",
      "\t [Batch 250 / 391] Train Loss: 3.040 \t Train Acc: 0.248\n",
      "\t [Batch 300 / 391] Train Loss: 2.824 \t Train Acc: 0.269\n",
      "\t [Batch 350 / 391] Train Loss: 2.664 \t Train Acc: 0.285\n",
      "Epoch 0:\t Train Loss: 2.551 \t Train Acc: 0.300\t Test Acc: 0.409\n",
      "Starting Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b509d0bdcffd496fb18e54f3365a0225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 1.574 \t Train Acc: 0.431\n",
      "\t [Batch 100 / 391] Train Loss: 1.534 \t Train Acc: 0.444\n",
      "\t [Batch 150 / 391] Train Loss: 1.510 \t Train Acc: 0.453\n",
      "\t [Batch 200 / 391] Train Loss: 1.484 \t Train Acc: 0.463\n",
      "\t [Batch 250 / 391] Train Loss: 1.458 \t Train Acc: 0.472\n",
      "\t [Batch 300 / 391] Train Loss: 1.431 \t Train Acc: 0.481\n",
      "\t [Batch 350 / 391] Train Loss: 1.407 \t Train Acc: 0.491\n",
      "Epoch 1:\t Train Loss: 1.393 \t Train Acc: 0.497\t Test Acc: 0.437\n",
      "Starting Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10de379f35f944268ca778b0e63df8db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 1.240 \t Train Acc: 0.563\n",
      "\t [Batch 100 / 391] Train Loss: 1.196 \t Train Acc: 0.575\n",
      "\t [Batch 150 / 391] Train Loss: 1.198 \t Train Acc: 0.575\n",
      "\t [Batch 200 / 391] Train Loss: 1.187 \t Train Acc: 0.579\n",
      "\t [Batch 250 / 391] Train Loss: 1.169 \t Train Acc: 0.586\n",
      "\t [Batch 300 / 391] Train Loss: 1.163 \t Train Acc: 0.588\n",
      "\t [Batch 350 / 391] Train Loss: 1.147 \t Train Acc: 0.594\n",
      "Epoch 2:\t Train Loss: 1.133 \t Train Acc: 0.599\t Test Acc: 0.483\n",
      "Starting Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811165f2405140468cf81019741c2013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.994 \t Train Acc: 0.648\n",
      "\t [Batch 100 / 391] Train Loss: 0.969 \t Train Acc: 0.655\n",
      "\t [Batch 150 / 391] Train Loss: 0.958 \t Train Acc: 0.660\n",
      "\t [Batch 200 / 391] Train Loss: 0.958 \t Train Acc: 0.662\n",
      "\t [Batch 250 / 391] Train Loss: 0.950 \t Train Acc: 0.665\n",
      "\t [Batch 300 / 391] Train Loss: 0.943 \t Train Acc: 0.668\n",
      "\t [Batch 350 / 391] Train Loss: 0.937 \t Train Acc: 0.670\n",
      "Epoch 3:\t Train Loss: 0.930 \t Train Acc: 0.673\t Test Acc: 0.470\n",
      "Starting Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc1cdaf3dce430ebf476e06ca393119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.814 \t Train Acc: 0.717\n",
      "\t [Batch 100 / 391] Train Loss: 0.815 \t Train Acc: 0.716\n",
      "\t [Batch 150 / 391] Train Loss: 0.809 \t Train Acc: 0.720\n",
      "\t [Batch 200 / 391] Train Loss: 0.804 \t Train Acc: 0.720\n",
      "\t [Batch 250 / 391] Train Loss: 0.798 \t Train Acc: 0.723\n",
      "\t [Batch 300 / 391] Train Loss: 0.793 \t Train Acc: 0.725\n",
      "\t [Batch 350 / 391] Train Loss: 0.790 \t Train Acc: 0.726\n",
      "Epoch 4:\t Train Loss: 0.792 \t Train Acc: 0.725\t Test Acc: 0.677\n",
      "Starting Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf45275ce63a4948a1a6e609366eae13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.696 \t Train Acc: 0.757\n",
      "\t [Batch 100 / 391] Train Loss: 0.684 \t Train Acc: 0.762\n",
      "\t [Batch 150 / 391] Train Loss: 0.695 \t Train Acc: 0.760\n",
      "\t [Batch 200 / 391] Train Loss: 0.698 \t Train Acc: 0.760\n",
      "\t [Batch 250 / 391] Train Loss: 0.696 \t Train Acc: 0.760\n",
      "\t [Batch 300 / 391] Train Loss: 0.688 \t Train Acc: 0.763\n",
      "\t [Batch 350 / 391] Train Loss: 0.690 \t Train Acc: 0.763\n",
      "Epoch 5:\t Train Loss: 0.685 \t Train Acc: 0.764\t Test Acc: 0.652\n",
      "Starting Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d746e0ccdd254490be2296d75a83e0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.558 \t Train Acc: 0.811\n",
      "\t [Batch 100 / 391] Train Loss: 0.594 \t Train Acc: 0.801\n",
      "\t [Batch 150 / 391] Train Loss: 0.590 \t Train Acc: 0.799\n",
      "\t [Batch 200 / 391] Train Loss: 0.602 \t Train Acc: 0.797\n",
      "\t [Batch 250 / 391] Train Loss: 0.603 \t Train Acc: 0.796\n",
      "\t [Batch 300 / 391] Train Loss: 0.604 \t Train Acc: 0.795\n",
      "\t [Batch 350 / 391] Train Loss: 0.599 \t Train Acc: 0.797\n",
      "Epoch 6:\t Train Loss: 0.594 \t Train Acc: 0.798\t Test Acc: 0.732\n",
      "Starting Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d39053ef834768919a2c0dffb3bb51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.535 \t Train Acc: 0.822\n",
      "\t [Batch 100 / 391] Train Loss: 0.516 \t Train Acc: 0.826\n",
      "\t [Batch 150 / 391] Train Loss: 0.528 \t Train Acc: 0.825\n",
      "\t [Batch 200 / 391] Train Loss: 0.525 \t Train Acc: 0.823\n",
      "\t [Batch 250 / 391] Train Loss: 0.522 \t Train Acc: 0.824\n",
      "\t [Batch 300 / 391] Train Loss: 0.521 \t Train Acc: 0.825\n",
      "\t [Batch 350 / 391] Train Loss: 0.518 \t Train Acc: 0.825\n",
      "Epoch 7:\t Train Loss: 0.518 \t Train Acc: 0.825\t Test Acc: 0.754\n",
      "Starting Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2555195c89c34b6aa8fa255476bf61a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.422 \t Train Acc: 0.859\n",
      "\t [Batch 100 / 391] Train Loss: 0.433 \t Train Acc: 0.854\n",
      "\t [Batch 150 / 391] Train Loss: 0.446 \t Train Acc: 0.848\n",
      "\t [Batch 200 / 391] Train Loss: 0.445 \t Train Acc: 0.848\n",
      "\t [Batch 250 / 391] Train Loss: 0.445 \t Train Acc: 0.849\n",
      "\t [Batch 300 / 391] Train Loss: 0.446 \t Train Acc: 0.848\n",
      "\t [Batch 350 / 391] Train Loss: 0.443 \t Train Acc: 0.849\n",
      "Epoch 8:\t Train Loss: 0.446 \t Train Acc: 0.848\t Test Acc: 0.709\n",
      "Starting Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc15cbe32d1d410fab6ae1a018909f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.350 \t Train Acc: 0.888\n",
      "\t [Batch 100 / 391] Train Loss: 0.382 \t Train Acc: 0.875\n",
      "\t [Batch 150 / 391] Train Loss: 0.375 \t Train Acc: 0.876\n",
      "\t [Batch 200 / 391] Train Loss: 0.377 \t Train Acc: 0.875\n",
      "\t [Batch 250 / 391] Train Loss: 0.381 \t Train Acc: 0.873\n",
      "\t [Batch 300 / 391] Train Loss: 0.378 \t Train Acc: 0.873\n",
      "\t [Batch 350 / 391] Train Loss: 0.381 \t Train Acc: 0.872\n",
      "Epoch 9:\t Train Loss: 0.386 \t Train Acc: 0.870\t Test Acc: 0.694\n",
      "Starting Epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94d21b69b954612adf3413f75bfec44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.299 \t Train Acc: 0.903\n",
      "\t [Batch 100 / 391] Train Loss: 0.307 \t Train Acc: 0.899\n",
      "\t [Batch 150 / 391] Train Loss: 0.314 \t Train Acc: 0.895\n",
      "\t [Batch 200 / 391] Train Loss: 0.317 \t Train Acc: 0.893\n",
      "\t [Batch 250 / 391] Train Loss: 0.314 \t Train Acc: 0.894\n",
      "\t [Batch 300 / 391] Train Loss: 0.315 \t Train Acc: 0.893\n",
      "\t [Batch 350 / 391] Train Loss: 0.321 \t Train Acc: 0.892\n",
      "Epoch 10:\t Train Loss: 0.325 \t Train Acc: 0.891\t Test Acc: 0.779\n",
      "Starting Epoch 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f81d76a19e248ae98e3bf9df9f141fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.222 \t Train Acc: 0.928\n",
      "\t [Batch 100 / 391] Train Loss: 0.214 \t Train Acc: 0.929\n",
      "\t [Batch 150 / 391] Train Loss: 0.229 \t Train Acc: 0.922\n",
      "\t [Batch 200 / 391] Train Loss: 0.252 \t Train Acc: 0.914\n",
      "\t [Batch 250 / 391] Train Loss: 0.258 \t Train Acc: 0.914\n",
      "\t [Batch 300 / 391] Train Loss: 0.261 \t Train Acc: 0.913\n",
      "\t [Batch 350 / 391] Train Loss: 0.261 \t Train Acc: 0.913\n",
      "Epoch 11:\t Train Loss: 0.262 \t Train Acc: 0.912\t Test Acc: 0.744\n",
      "Starting Epoch 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69cbe106ef64d8a81bcd8ed2d2e9515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.224 \t Train Acc: 0.937\n",
      "\t [Batch 100 / 391] Train Loss: 0.208 \t Train Acc: 0.939\n",
      "\t [Batch 150 / 391] Train Loss: 0.191 \t Train Acc: 0.943\n",
      "\t [Batch 200 / 391] Train Loss: 0.206 \t Train Acc: 0.938\n",
      "\t [Batch 250 / 391] Train Loss: 0.222 \t Train Acc: 0.935\n",
      "\t [Batch 300 / 391] Train Loss: 0.217 \t Train Acc: 0.936\n",
      "\t [Batch 350 / 391] Train Loss: 0.214 \t Train Acc: 0.936\n",
      "Epoch 12:\t Train Loss: 0.213 \t Train Acc: 0.936\t Test Acc: 0.793\n",
      "Starting Epoch 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fada3e7615844d1b08ecf4c9b1b1a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.111 \t Train Acc: 0.970\n",
      "\t [Batch 100 / 391] Train Loss: 0.098 \t Train Acc: 0.972\n",
      "\t [Batch 150 / 391] Train Loss: 0.091 \t Train Acc: 0.974\n",
      "\t [Batch 200 / 391] Train Loss: 0.098 \t Train Acc: 0.971\n",
      "\t [Batch 250 / 391] Train Loss: 0.102 \t Train Acc: 0.970\n",
      "\t [Batch 300 / 391] Train Loss: 0.122 \t Train Acc: 0.965\n",
      "\t [Batch 350 / 391] Train Loss: 0.132 \t Train Acc: 0.961\n",
      "Epoch 13:\t Train Loss: 0.138 \t Train Acc: 0.959\t Test Acc: 0.741\n",
      "Starting Epoch 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26341878694f48d382dddf3b3b544846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.059 \t Train Acc: 0.985\n",
      "\t [Batch 100 / 391] Train Loss: 0.054 \t Train Acc: 0.986\n",
      "\t [Batch 150 / 391] Train Loss: 0.050 \t Train Acc: 0.987\n",
      "\t [Batch 200 / 391] Train Loss: 0.055 \t Train Acc: 0.986\n",
      "\t [Batch 250 / 391] Train Loss: 0.053 \t Train Acc: 0.987\n",
      "\t [Batch 300 / 391] Train Loss: 0.053 \t Train Acc: 0.986\n",
      "\t [Batch 350 / 391] Train Loss: 0.070 \t Train Acc: 0.982\n",
      "Epoch 14:\t Train Loss: 0.079 \t Train Acc: 0.980\t Test Acc: 0.824\n",
      "Starting Epoch 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260b56e2498749e586c8e3e83c6d7edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.033 \t Train Acc: 0.993\n",
      "\t [Batch 100 / 391] Train Loss: 0.028 \t Train Acc: 0.994\n",
      "\t [Batch 150 / 391] Train Loss: 0.026 \t Train Acc: 0.995\n",
      "\t [Batch 200 / 391] Train Loss: 0.026 \t Train Acc: 0.995\n",
      "\t [Batch 250 / 391] Train Loss: 0.026 \t Train Acc: 0.995\n",
      "\t [Batch 300 / 391] Train Loss: 0.025 \t Train Acc: 0.996\n",
      "\t [Batch 350 / 391] Train Loss: 0.025 \t Train Acc: 0.995\n",
      "Epoch 15:\t Train Loss: 0.025 \t Train Acc: 0.995\t Test Acc: 0.843\n",
      "Starting Epoch 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17c822178a345899a76cc378a0062d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.011 \t Train Acc: 0.999\n",
      "\t [Batch 100 / 391] Train Loss: 0.010 \t Train Acc: 0.999\n",
      "\t [Batch 150 / 391] Train Loss: 0.010 \t Train Acc: 1.000\n",
      "\t [Batch 200 / 391] Train Loss: 0.009 \t Train Acc: 1.000\n",
      "\t [Batch 250 / 391] Train Loss: 0.009 \t Train Acc: 0.999\n",
      "\t [Batch 300 / 391] Train Loss: 0.009 \t Train Acc: 1.000\n",
      "\t [Batch 350 / 391] Train Loss: 0.009 \t Train Acc: 0.999\n",
      "Epoch 16:\t Train Loss: 0.009 \t Train Acc: 0.999\t Test Acc: 0.857\n",
      "Starting Epoch 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930c756b44e046b6a35761a74f4dceac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.005 \t Train Acc: 1.000\n",
      "\t [Batch 100 / 391] Train Loss: 0.005 \t Train Acc: 1.000\n",
      "\t [Batch 150 / 391] Train Loss: 0.005 \t Train Acc: 1.000\n",
      "\t [Batch 200 / 391] Train Loss: 0.005 \t Train Acc: 1.000\n",
      "\t [Batch 250 / 391] Train Loss: 0.005 \t Train Acc: 1.000\n",
      "\t [Batch 300 / 391] Train Loss: 0.004 \t Train Acc: 1.000\n",
      "\t [Batch 350 / 391] Train Loss: 0.004 \t Train Acc: 1.000\n",
      "Epoch 17:\t Train Loss: 0.004 \t Train Acc: 1.000\t Test Acc: 0.854\n",
      "Starting Epoch 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f15c6d7b5ca4349956bdcfbd5be3b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.003 \t Train Acc: 1.000\n",
      "\t [Batch 100 / 391] Train Loss: 0.003 \t Train Acc: 1.000\n",
      "\t [Batch 150 / 391] Train Loss: 0.003 \t Train Acc: 1.000\n",
      "\t [Batch 200 / 391] Train Loss: 0.003 \t Train Acc: 1.000\n",
      "\t [Batch 250 / 391] Train Loss: 0.003 \t Train Acc: 1.000\n",
      "\t [Batch 300 / 391] Train Loss: 0.003 \t Train Acc: 1.000\n",
      "\t [Batch 350 / 391] Train Loss: 0.003 \t Train Acc: 1.000\n",
      "Epoch 18:\t Train Loss: 0.003 \t Train Acc: 1.000\t Test Acc: 0.860\n",
      "Starting Epoch 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5159198ca8eb4598bbbf97d04e813df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Batch 50 / 391] Train Loss: 0.002 \t Train Acc: 1.000\n",
      "\t [Batch 100 / 391] Train Loss: 0.002 \t Train Acc: 1.000\n",
      "\t [Batch 150 / 391] Train Loss: 0.002 \t Train Acc: 1.000\n",
      "\t [Batch 200 / 391] Train Loss: 0.002 \t Train Acc: 1.000\n",
      "\t [Batch 250 / 391] Train Loss: 0.002 \t Train Acc: 1.000\n",
      "\t [Batch 300 / 391] Train Loss: 0.002 \t Train Acc: 1.000\n",
      "\t [Batch 350 / 391] Train Loss: 0.002 \t Train Acc: 1.000\n",
      "Epoch 19:\t Train Loss: 0.002 \t Train Acc: 1.000\t Test Acc: 0.861\n"
     ]
    }
   ],
   "source": [
    "model = make_cnn()\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "epochs = 20\n",
    "for i in range(epochs):\n",
    "    print(f'Starting Epoch {i}')\n",
    "    train_loss, train_acc = train_epoch(model, train_dl, opt)\n",
    "    test_loss, test_acc = evaluate(model, test_dl)\n",
    "    \n",
    "    print(f'Epoch {i}:\\t Train Loss: {train_loss:.3f} \\t Train Acc: {train_acc:.3f}\\t Test Acc: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-medicaid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
